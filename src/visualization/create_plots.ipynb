{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Horizon Plots\n",
    "\n",
    "@author: jhuthmacher\n",
    "\n",
    "This notebook shows how to use the high level plotting API.\n",
    "\n",
    "It is structured as follows:\n",
    "\n",
    "1. Import necessary modules\n",
    "2. Load raw data (features + proton intensities)\n",
    "3. Load model data (predictions + observations)\n",
    "4. Plots\n",
    "\n",
    "The functions that are used here are a high level api functions for the deep horizon plotting mechanism and, therefore, doesn't have any customization possibilities. In general, all functions just require the **data** (in the correct format!) and you could also handover a **path**, where the plot should be saved. The **path** is not mandatory and if it is not provided it will use some default path (e.g. `figures/proton_intensities_relations.pdf`). Important, the path needs the **file name at the end**!\n",
    "\n",
    "## Plotting API structure\n",
    "\n",
    "Python file `src.visualization.plot_results.py` (located in `src.visualization`) - Plotting functions :\n",
    "* This file contains all underlying functions for creating the plots\n",
    "* When you have to adapt things this would be a place to look at. Be carfeul to not destroy the general usage.\n",
    "\n",
    "## About the plotting mechanism\n",
    "The  plotting API is devided in different parts you can use depending on your need for customization. \n",
    "\n",
    "1. **Generator Functions (high level API)**\n",
    "\n",
    "For each plot that is available yet you have a so called *generator function* that just creates the plot with default settings and without the possibility to adapt things. This notebooks only contains generator functions! They are located in `visualization.plot_results`\n",
    "\n",
    "A list of all generator functions:\n",
    "* `generate_feature_imp_plot`: Creates feature importance plot\n",
    "* `generate_correlation_matrix`: Creates correlation matrix\n",
    "* `generate_pos_distr`: Creates the positional distribution plots for X, Y, Z\n",
    "* `generate_pos_intensity_heatmaps`: Creates the intensity distribution for X, Y, Z (mean as aggregation)\n",
    "* `generate_pred_heatmaps`: Creates the prediction vs. observation heatmaps\n",
    "* `generate_proton_relation_plot`: Creates proton/feature relation plot (Figure 3)\n",
    "* `generate_feature_distr`: Creates distribution plots for features\n",
    "\n",
    "## Data Structure for Plotting\n",
    "To us the plot function one have to handover the correct data in the expected format. Below you find a brief description about how the data files that are not automatically downloaded should be organized on your machine. This mostly relates to the model data such as predictions or feature importances.\n",
    "\n",
    "```\n",
    "model_path = ./model/\n",
    "test_path = ./model/obs_vs_pred_csv/test/\n",
    "train_path = ./model/obs_vs_pred_csv/train/\n",
    "fi_path = ./model/feature_imp_csv/test/\n",
    "\n",
    "+-- model\n",
    "    +-- feature_imp_csv\n",
    "    |   +-- test\n",
    "    |       +-- fi_ch1_test.csv\n",
    "    |       +-- fi_ch2_test.csv\n",
    "    |       +-- fi_ch3_test.csv\n",
    "    |       +-- fi_ch4_test.csv\n",
    "    |       +-- fi_ch5_test.csv\n",
    "    +-- obs_vs_pred_csv\n",
    "        +-- test\n",
    "        |   +-- p1_obs_vs_predict.csv\n",
    "        |   +-- p2_obs_vs_predict.csv\n",
    "        |   +-- p3_obs_vs_predict.csv\n",
    "        |   +-- p4_obs_vs_predict.csv\n",
    "        |   +-- p5_obs_vs_predict.csv\n",
    "        +-- train\n",
    "            +-- p1_obs_vs_predict.csv\n",
    "            +-- p2_obs_vs_predict.csv\n",
    "            +-- p3_obs_vs_predict.csv\n",
    "            +-- p4_obs_vs_predict.csv\n",
    "            +-- p5_obs_vs_predict.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Imports #\n",
    "###########\n",
    "\n",
    "# Load notebook magic for reloading packages automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime\n",
    "\n",
    "############################\n",
    "# Stlying for presentation #\n",
    "############################\n",
    "plt.style.use('seaborn')\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Data Loading #\n",
    "################\n",
    "from utils.data_utils import load_data\n",
    "\n",
    "dataLog10, data, _, _ = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Load Model Data  #\n",
    "####################\n",
    "from utils.data_utils import load_model_data\n",
    "\n",
    "# For details have a look at the initial description\n",
    "test_path = \"../data/model/obs_vs_pred_csv/test/\"  # SET_PATH\n",
    "train_path = \"../data/model/obs_vs_pred_csv/train/\"  # SET_PATH\n",
    "\n",
    "dfs1 = load_model_data(test_path, channels=[1, 2, 3, 4, 5])\n",
    "dfs1_train = load_model_data(train_path, channels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Load Feature Importances #\n",
    "############################\n",
    "from utils.data_utils import load_feature_importances\n",
    "\n",
    "# For details have a look at the initial description\n",
    "fi_path = \"../data/model/feature_imp_csv/test/\"  # SET_PATH\n",
    "\n",
    "df_feature_imp2 = load_feature_importances(fi_path, mode=\"test\", channels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Feature Importance #\n",
    "######################\n",
    "from visualization.plot_results import generate_feature_imp_plot\n",
    "\n",
    "# Merge combined features\n",
    "df_feature_imp2[\"feature\"] = df_feature_imp2[\"feature\"].str.replace(\"_combined\", \"\")\n",
    "\n",
    "generate_feature_imp_plot(df_feature_imp2, pivot=\"feature\", val=\"perm_imp\", fmt=\"1.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Correlation Matrix #\n",
    "######################\n",
    "from visualization.plot_results import generate_correlation_matrix\n",
    "generate_correlation_matrix(dataLog10[dataLog10.columns[:-7]].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Positional Distribution Plot #\n",
    "################################\n",
    "from visualization.plot_results import generate_pos_distr\n",
    "generate_pos_distr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Positional Intensity Heatmaps #\n",
    "#################################\n",
    "from visualization.plot_results import generate_pos_intensity_heatmaps\n",
    "generate_pos_intensity_heatmaps(dataLog10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Prediction Heatmaps #\n",
    "#######################\n",
    "from visualization.plot_results import generate_pred_heatmap\n",
    "import matplotlib\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "          'axes.labelsize': 'xx-large',\n",
    "          'axes.titlesize':'xx-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "matplotlib.rcParams.update(params)\n",
    "\n",
    "channels = [0, 1, 3, 3, 4]\n",
    "\n",
    "for ch in channels:\n",
    "    train = dfs1_train[ch]\n",
    "    test = dfs1[ch]\n",
    "    generate_pred_heatmap(train, test, annotated_text=f\"Channel {ch + 1}\",\n",
    "                          path=f\".figures/prediction_heatmap_ch{ch+1}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Time Plot #\n",
    "#############\n",
    "from visualization.plot_results import plot_pred_obs_time\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "start_date = datetime(2015, 9, 19, 1, 15)\n",
    "end_date = datetime(2015, 9, 19, 20, 30)\n",
    "\n",
    "fig = plot_pred_obs_time(dfs1, save_plot=True, idx_range=(start_date, end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Proton Feature Relation #\n",
    "###########################\n",
    "from visualization.plot_results import generate_proton_relation_plot\n",
    "\n",
    "generate_proton_relation_plot(dataLog10, channel=\"p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Distribution Plots #\n",
    "######################\n",
    "from visualization.plot_results import generate_feature_distr\n",
    "generate_feature_distr(dataLog10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('pbds20': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f1d83d25a9953267b10830d25b24848ac3bff5168bf283110304bc225028f792"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
